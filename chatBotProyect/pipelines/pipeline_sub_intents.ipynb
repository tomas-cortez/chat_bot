{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "nlp=spacy.load('es_core_news_sm')\n",
    "\n",
    "# Stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "spanish_stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "# Levantamos la lista de StopWords\n",
    "f = open('stopwords_intents.txt', 'r', encoding='utf8')\n",
    "stopwords = f.read().split('\\n')\n",
    "f.close()\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcesar(Corpus, POS=False, Lema=True, Stem=True):\n",
    "    \n",
    "    \n",
    "    # Generar una lista de documentos de spacy para tratar el POS Tagging y la Lematización\n",
    "    docs=[]\n",
    "    for oracion in Corpus:\n",
    "        docs.append(nlp(oracion.lower())) #La lematización funciona mejor en minúsculas\n",
    "    \n",
    "    # Crear una lista de oraciones, donde cada elemento es una lista de palabras.\n",
    "    # Cada palabra está definida por una tupla (Texto, POSTag, Lema)\n",
    "    # Se omiten los tokens que son identificados como signos de puntuación\n",
    "    oraciones=[]\n",
    "    for doc in docs:\n",
    "        oracion=[]\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'PUNCT':\n",
    "                oracion.append((token.text, token.pos_, token.lemma_))\n",
    "        oraciones.append(oracion)\n",
    "    \n",
    "    # Removemos StopWords (finándonos en el lema de cada palabra en vez de su texto!)\n",
    "    # No conviene quitar las StopWords antes de lematizar pues son útiles para ese proceso...\n",
    "    oraciones = [[palabra for palabra in oracion if palabra[2] not in stopwords] for oracion in oraciones]\n",
    "    \n",
    "    # Stemming\n",
    "    if Stem==True:\n",
    "        oraciones_aux=[]\n",
    "        for oracion in oraciones:\n",
    "            oracion_aux=[]\n",
    "            for palabra in oracion:\n",
    "                p_texto, p_pos, p_lema = palabra\n",
    "                # Si Lema es True, se Stemmatiza el lema; si no, se Stemmatiza la palabra original\n",
    "                if Lema==True:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_lema)))\n",
    "                else:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_texto)))\n",
    "            oraciones_aux.append(oracion_aux)\n",
    "        \n",
    "        oraciones = oraciones_aux\n",
    "    \n",
    "    # Finalmente: devolver nuevamente una lista de cadenas como la recibida, pero con el contenido\n",
    "    # de cada cadena conformado según los parámetros:\n",
    "    \n",
    "    Corpus_Procesado = [] #Variable de salida\n",
    "    \n",
    "    for doc in oraciones:\n",
    "        oracion = ''\n",
    "        for palabra in doc:\n",
    "            if Stem == True:\n",
    "                # Devolver cadena de Stemming\n",
    "                oracion = oracion + palabra[3]\n",
    "            else:\n",
    "                if Lema == True:\n",
    "                    # Devolver cadena de Lemas\n",
    "                    oracion = oracion + palabra[2]\n",
    "                else:\n",
    "                    # Devolver cadena de palabras originales\n",
    "                    oracion = oracion + palabra[0]\n",
    "            \n",
    "            if POS == True:\n",
    "                #Concatenar POS a cada palabra\n",
    "                oracion = oracion + '_' + palabra[1].lower()\n",
    "            \n",
    "            oracion = oracion + ' '\n",
    "        \n",
    "        Corpus_Procesado.append(oracion)\n",
    "        \n",
    "    return Corpus_Procesado\n",
    "\n",
    "def Corregir_Documentos(df_textos, columnas, POS=False, Lema=True, Stem=True):\n",
    "\n",
    "    for col in columnas:\n",
    "        df_textos[col] = PreProcesar(list(df_textos[col]), POS, Lema, Stem)\n",
    "    \n",
    "    # Sanear el DataFrame eliminando los duplicados y reindexándolo\n",
    "    df_textos = df_textos.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return df_textos\n",
    "\n",
    "def Generar_Matriz_BOW(df_textos, columna, binario=False, ngram=(1,2)):\n",
    "    \n",
    "    # Vectorizar, usando CountVectorizer de sklearn.feature_extraction.text\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizador = CountVectorizer(binary=binario, ngram_range=ngram)\n",
    "    X = vectorizador.fit_transform(df_textos[columna])\n",
    "    \n",
    "    # Generar el DataFrame a devolver\n",
    "    df_X = pd.DataFrame(X.toarray(), columns=vectorizador.get_feature_names())\n",
    "    df = df_textos.join(df_X)\n",
    "    \n",
    "    return vectorizador, df\n",
    "\n",
    "def Generar_Matriz_Tfidf(df_textos, columna, ngram=(1,2)):\n",
    "    \n",
    "    # Vectorizar... Directamente usar aquí el TfidfVectorizer de sklearn en vez del CountVectorizer\n",
    "    # (Lleva los mismos parámetros y directamente nos devuelve la matriz con los vectores Tf*Idf)\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizador = TfidfVectorizer(ngram_range=ngram)\n",
    "    X = vectorizador.fit_transform(df_textos[columna])\n",
    "    \n",
    "    # Generar el DataFrame a devolver\n",
    "    df_X = pd.DataFrame(X.toarray(), columns=vectorizador.get_feature_names())\n",
    "    df = df_textos.join(df_X)\n",
    "    \n",
    "    return vectorizador, df\n",
    "\n",
    "def Distancia_Coseno(u, v):\n",
    "    \n",
    "    distancia = 1.0 - (np.dot(u, v) / (np.sqrt(sum(np.square(u))) * np.sqrt(sum(np.square(v)))))\n",
    "    return distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#1. Cargar y corregir el corpus\n",
    "df_textos = pd.read_csv('data_intents.csv', sep=';', encoding='utf_8')\n",
    "df_textos = Corregir_Documentos(df_textos,['oracion'],False,True,True)\n",
    "\n",
    "#2. Modelizar los documentos de df_textos\n",
    "vectorizador, df_textos = Generar_Matriz_Tfidf(df_textos,'oracion',ngram=(1,3))\n",
    "#vectorizador, df_textos = Generar_Matriz_BOW(df_textos,'oracion')\n",
    "\n",
    "#3. Separar el corpus en Train/Test\n",
    "X = df_textos.drop([\"intencion\",\"subIntencion\"],axis=1)\n",
    "y = df_textos[[\"subIntencion\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=124)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "      <th>intencion</th>\n",
       "      <th>subIntencion</th>\n",
       "      <th>abiert</th>\n",
       "      <th>abiert institut</th>\n",
       "      <th>abon</th>\n",
       "      <th>abon tarjet</th>\n",
       "      <th>abon vari</th>\n",
       "      <th>abon vari semestr</th>\n",
       "      <th>abrir</th>\n",
       "      <th>...</th>\n",
       "      <th>vo</th>\n",
       "      <th>vo estudiari</th>\n",
       "      <th>vo podes</th>\n",
       "      <th>vo podes inform</th>\n",
       "      <th>votast</th>\n",
       "      <th>web</th>\n",
       "      <th>web ies</th>\n",
       "      <th>web ies dict</th>\n",
       "      <th>web ies ver</th>\n",
       "      <th>xxi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ies</td>\n",
       "      <td>charla</td>\n",
       "      <td>todas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cual direccion i</td>\n",
       "      <td>charla</td>\n",
       "      <td>todas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cual direccion</td>\n",
       "      <td>charla</td>\n",
       "      <td>todas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dond qued ies</td>\n",
       "      <td>charla</td>\n",
       "      <td>todas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hol</td>\n",
       "      <td>charla</td>\n",
       "      <td>todas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>quer inform practic laboral colegi</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>pod pas inform event ten program</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>tip alianz institucional ten</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>local ten oficin</td>\n",
       "      <td>generalidades</td>\n",
       "      <td>todas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>falt materi secundari pod anot igual</td>\n",
       "      <td>tramites</td>\n",
       "      <td>requisitos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>783 rows × 2778 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   oracion      intencion subIntencion  \\\n",
       "0                                     ies          charla        todas   \n",
       "1                        cual direccion i          charla        todas   \n",
       "2                          cual direccion          charla        todas   \n",
       "3                           dond qued ies          charla        todas   \n",
       "4                                     hol          charla        todas   \n",
       "..                                     ...            ...          ...   \n",
       "778    quer inform practic laboral colegi   generalidades        todas   \n",
       "779      pod pas inform event ten program   generalidades        todas   \n",
       "780          tip alianz institucional ten   generalidades        todas   \n",
       "781                      local ten oficin   generalidades        todas   \n",
       "782  falt materi secundari pod anot igual        tramites   requisitos   \n",
       "\n",
       "     abiert  abiert institut  abon  abon tarjet  abon vari  abon vari semestr  \\\n",
       "0       0.0              0.0   0.0          0.0        0.0                0.0   \n",
       "1       0.0              0.0   0.0          0.0        0.0                0.0   \n",
       "2       0.0              0.0   0.0          0.0        0.0                0.0   \n",
       "3       0.0              0.0   0.0          0.0        0.0                0.0   \n",
       "4       0.0              0.0   0.0          0.0        0.0                0.0   \n",
       "..      ...              ...   ...          ...        ...                ...   \n",
       "778     0.0              0.0   0.0          0.0        0.0                0.0   \n",
       "779     0.0              0.0   0.0          0.0        0.0                0.0   \n",
       "780     0.0              0.0   0.0          0.0        0.0                0.0   \n",
       "781     0.0              0.0   0.0          0.0        0.0                0.0   \n",
       "782     0.0              0.0   0.0          0.0        0.0                0.0   \n",
       "\n",
       "     abrir  ...   vo  vo estudiari  vo podes  vo podes inform  votast  web  \\\n",
       "0      0.0  ...  0.0           0.0       0.0              0.0     0.0  0.0   \n",
       "1      0.0  ...  0.0           0.0       0.0              0.0     0.0  0.0   \n",
       "2      0.0  ...  0.0           0.0       0.0              0.0     0.0  0.0   \n",
       "3      0.0  ...  0.0           0.0       0.0              0.0     0.0  0.0   \n",
       "4      0.0  ...  0.0           0.0       0.0              0.0     0.0  0.0   \n",
       "..     ...  ...  ...           ...       ...              ...     ...  ...   \n",
       "778    0.0  ...  0.0           0.0       0.0              0.0     0.0  0.0   \n",
       "779    0.0  ...  0.0           0.0       0.0              0.0     0.0  0.0   \n",
       "780    0.0  ...  0.0           0.0       0.0              0.0     0.0  0.0   \n",
       "781    0.0  ...  0.0           0.0       0.0              0.0     0.0  0.0   \n",
       "782    0.0  ...  0.0           0.0       0.0              0.0     0.0  0.0   \n",
       "\n",
       "     web ies  web ies dict  web ies ver  xxi  \n",
       "0        0.0           0.0          0.0  0.0  \n",
       "1        0.0           0.0          0.0  0.0  \n",
       "2        0.0           0.0          0.0  0.0  \n",
       "3        0.0           0.0          0.0  0.0  \n",
       "4        0.0           0.0          0.0  0.0  \n",
       "..       ...           ...          ...  ...  \n",
       "778      0.0           0.0          0.0  0.0  \n",
       "779      0.0           0.0          0.0  0.0  \n",
       "780      0.0           0.0          0.0  0.0  \n",
       "781      0.0           0.0          0.0  0.0  \n",
       "782      0.0           0.0          0.0  0.0  \n",
       "\n",
       "[783 rows x 2778 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparativa = pd.DataFrame(columns=['Modelo','Umbral','Aciertos',\n",
    "'Errores','Indeterm','Precision','Recall','Accuracy','F1','df_Aciertos','df_Errores','df_Indeterm'])\n",
    "\n",
    "#Distancia_Coseno del profe\n",
    "\n",
    "def Evaluar_Modelo_Distancia_Coseno(X_train, X_test, y_test, umbral=0.8):\n",
    "    # Recorrer todo el Test Set prediciendo para cada oración de X_test y comparando con y_test\n",
    "    global df_comparativa\n",
    "    df_test = X_test[['oracion']].join(y_test)\n",
    "    array_X = X_train[X_train.columns[1:]].values\n",
    "    lista_distancia = [] #Distancia con el elemento más cercano (predicción)\n",
    "    lista_predic    = [] #Predicción del elemento más cercano\n",
    "    lista_similar   = [] #Texto del elemento más cercano\n",
    "    for test_doc in df_test.iterrows():\n",
    "        i,d = test_doc\n",
    "        df_query = pd.DataFrame([d['oracion']],columns=['oracion'])\n",
    "        Q = vectorizador.transform(df_query['oracion'])\n",
    "        distancia = [Distancia_Coseno(Q.A[0],fila) for fila in array_X]\n",
    "        df_Resultado = pd.DataFrame(distancia, columns=['Distancia']).join(X_train[['oracion']]).join(y_train[['subIntencion']]).sort_values(by='Distancia').head(1)\n",
    "\n",
    "        lista_distancia.append(df_Resultado.iloc[0]['Distancia'])\n",
    "        lista_predic.append(df_Resultado.iloc[0]['subIntencion']) \n",
    "        lista_similar.append(df_Resultado.iloc[0]['oracion'])\n",
    "\n",
    "    # Agregar columnas con resultados predichos al df_test\n",
    "    df_test['Distancia'] = lista_distancia\n",
    "    df_test['Predic']    = lista_predic\n",
    "    df_test['Similar']   = lista_similar\n",
    "\n",
    "    # Evaluar el resultado en df_test\n",
    "    print('Cantidad de registros evaluados:', len(df_test))\n",
    "    print('--------------------')\n",
    "    aciertos = df_test[ ( df_test['subIntencion'] == df_test['Predic'] ) & \n",
    "                        ( df_test['Distancia'] <= umbral ) ]['subIntencion'].count()\n",
    "    errores  = df_test[ ( df_test['subIntencion'] != df_test['Predic'] ) & \n",
    "                        ( df_test['Distancia'] <= umbral) ]['subIntencion'].count()\n",
    "    indeterm = df_test[ ( df_test['Distancia'] > umbral) ]['Distancia'].count()\n",
    "    print('Aciertos:', aciertos)\n",
    "    print('Errores :', errores)\n",
    "    print('Indeterm:', indeterm)\n",
    "    print('--------------------')\n",
    "    precision = aciertos/(aciertos+errores)\n",
    "    recall    = aciertos/(aciertos+indeterm)\n",
    "    accuracy  = (aciertos+indeterm)/(aciertos+errores+indeterm)\n",
    "    F1        = 2*((precision*recall)/(precision+recall))\n",
    "    print('Precision: {0:.3f} <- aciertos/(aciertos+errores)'.format(precision))\n",
    "    print('Recall   : {0:.3f} <- aciertos/(aciertos+indeterm)'.format(recall))\n",
    "    print('Accuracy : {0:.3f} <- (aciertos+indeterm)/(aciertos+errores+indeterm)'.format(accuracy))\n",
    "    print('F1       : {0:.3f} <- 2*((precision*recall)/(precision+recall))'.format(F1))\n",
    "\n",
    "    df_comparativa = df_comparativa.append({'Modelo': 'Distancia coseno',\n",
    "                                            'Umbral': umbral,\n",
    "                                            'Aciertos': aciertos,\n",
    "                                            'Errores': errores,\n",
    "                                            'Indeterm': indeterm,\n",
    "                                            'Precision': precision,\n",
    "                                            'Recall': recall,\n",
    "                                            'Accuracy': accuracy,\n",
    "                                            'F1': F1,\n",
    "                                            'df_Aciertos': df_test[ ( df_test['subIntencion'] == df_test['Predic'] ) & ( df_test['Distancia'] <= umbral ) ],\n",
    "                                            'df_Errores' : df_test[ ( df_test['subIntencion'] != df_test['Predic'] ) & ( df_test['Distancia'] <= umbral ) ],\n",
    "                                            'df_Indeterm': df_test[ ( df_test['Distancia'] > umbral ) ]\n",
    "                                            }, ignore_index=True)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros evaluados: 157\n",
      "--------------------\n",
      "Aciertos: 122\n",
      "Errores : 14\n",
      "Indeterm: 21\n",
      "--------------------\n",
      "Precision: 0.897 <- aciertos/(aciertos+errores)\n",
      "Recall   : 0.853 <- aciertos/(aciertos+indeterm)\n",
      "Accuracy : 0.911 <- (aciertos+indeterm)/(aciertos+errores+indeterm)\n",
      "F1       : 0.875 <- 2*((precision*recall)/(precision+recall))\n"
     ]
    }
   ],
   "source": [
    "Evaluar_Modelo_Distancia_Coseno(X_train, X_test, y_test, umbral=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\tomas\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor accuracy: 0.8498\n",
      "Mejor C: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear el modelo con los parámetros que no cambiarán: observar que no le pasamos el valor de C de regulrización\n",
    "RLog=LogisticRegression(penalty='none', max_iter=10000, tol=0.0001, multi_class='ovr',)\n",
    "\n",
    "# Armar el diccionario con el nombre y valores para los Hiperparámetros\n",
    "parametros_RLog = {'C':[1]}\n",
    "\n",
    "# Armar el GridSearchCV\n",
    "grid_RLog = GridSearchCV(estimator = RLog,scoring = 'accuracy',param_grid = parametros_RLog, cv = 5,\n",
    "                        n_jobs = -1)\n",
    "\n",
    "# Entrenar con el Train Set\n",
    "grid_RLog.fit(X_train[X_train.columns[1:]].values, y_train);\n",
    "\n",
    "# Obtener el mejor AC \n",
    "AC_RLog_best=grid_RLog.best_score_\n",
    "print('Mejor accuracy: ' + str(round(AC_RLog_best,4)))\n",
    "\n",
    "C_RLog_best=grid_RLog.best_params_ \n",
    "print('Mejor C: ' + str(C_RLog_best))\n",
    "###########################################################################################################\n",
    "def Evaluar_Modelo(modelo, nombre_modelo, X_test, y_test, umbral=0.7):\n",
    "    # Recorrer todo el Test Set prediciendo para cada oración de X_test y comparando con y_test\n",
    "    global df_comparativa\n",
    "    df_test = X_test[['oracion']].join(y_test)\n",
    "    lista_predic       = [] #Predicción\n",
    "    lista_probabilidad = [] #Probabilidad de la predicción\n",
    "    for test_doc in df_test.iterrows():\n",
    "        i,d = test_doc\n",
    "        df_query = pd.DataFrame([d['oracion']],columns=['oracion'])\n",
    "        Q = vectorizador.transform(df_query['oracion'])\n",
    "        pronostico = modelo.predict([Q.A[0]])\n",
    "        probabilidad = modelo.predict_proba([Q.A[0]])\n",
    "        lista_predic.append(pronostico[0])\n",
    "        lista_probabilidad.append(probabilidad[0].max())\n",
    "    \n",
    "    # Agregar columnas con resultados predichos al df_test\n",
    "    df_test['Probabilidad'] = lista_probabilidad\n",
    "    df_test['Predic'] = lista_predic\n",
    "    \n",
    "    # Evaluar el resultado en df_test\n",
    "    print('Cantidad de registros evaluados:', len(df_test))\n",
    "    print('--------------------')\n",
    "    aciertos = df_test[ ( df_test['subIntencion'] == df_test['Predic'] ) & \n",
    "                        ( df_test['Probabilidad'] >= umbral ) ]['subIntencion'].count()\n",
    "    errores  = df_test[ ( df_test['subIntencion'] != df_test['Predic'] ) & \n",
    "                        ( df_test['Probabilidad'] >= umbral) ]['subIntencion'].count()\n",
    "    indeterm = df_test[ ( df_test['Probabilidad'] < umbral) ]['Probabilidad'].count()\n",
    "    \n",
    "    print('Aciertos:', aciertos)\n",
    "    print('Errores :', errores)\n",
    "    print('Indeterm:', indeterm)\n",
    "    print('--------------------')\n",
    "    precision = aciertos/(aciertos+errores)\n",
    "    recall    = aciertos/(aciertos+indeterm)\n",
    "    accuracy  = (aciertos+indeterm)/(aciertos+errores+indeterm)\n",
    "    F1        = 2*((precision*recall)/(precision+recall))\n",
    "    print('Precision: {0:.3f} <- aciertos/(aciertos+errores)'.format(precision))\n",
    "    print('Recall   : {0:.3f} <- aciertos/(aciertos+indeterm)'.format(recall))\n",
    "    print('Accuracy : {0:.3f} <- (aciertos+indeterm)/(aciertos+errores+indeterm)'.format(accuracy))\n",
    "    print('F1       : {0:.3f} <- 2*((precision*recall)/(precision+recall))'.format(F1))\n",
    "\n",
    "    # Registrar Resultados\n",
    "    df_comparativa = df_comparativa.append({'Modelo': nombre_modelo,\n",
    "                                            'Umbral': umbral,\n",
    "                                            'Aciertos': aciertos,\n",
    "                                            'Errores': errores,\n",
    "                                            'Indeterm': indeterm,\n",
    "                                            'Precision': precision,\n",
    "                                            'Recall': recall,\n",
    "                                            'Accuracy': accuracy,\n",
    "                                            'F1': F1,\n",
    "                                            'df_Aciertos': df_test[ ( df_test['subIntencion'] == df_test['Predic'] ) & ( df_test['Probabilidad'] >= umbral ) ],\n",
    "                                            'df_Errores' : df_test[ ( df_test['subIntencion'] != df_test['Predic'] ) & ( df_test['Probabilidad'] >= umbral ) ],\n",
    "                                            'df_Indeterm': df_test[ ( df_test['Probabilidad'] < umbral ) ]\n",
    "                                            }, ignore_index=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros evaluados: 157\n",
      "--------------------\n",
      "Aciertos: 139\n",
      "Errores : 14\n",
      "Indeterm: 4\n",
      "--------------------\n",
      "Precision: 0.908 <- aciertos/(aciertos+errores)\n",
      "Recall   : 0.972 <- aciertos/(aciertos+indeterm)\n",
      "Accuracy : 0.911 <- (aciertos+indeterm)/(aciertos+errores+indeterm)\n",
      "F1       : 0.939 <- 2*((precision*recall)/(precision+recall))\n"
     ]
    }
   ],
   "source": [
    "Evaluar_Modelo(grid_RLog, 'Regresión Logística Sin Regularización', X_test, y_test, umbral=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Umbral</th>\n",
       "      <th>Aciertos</th>\n",
       "      <th>Errores</th>\n",
       "      <th>Indeterm</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>df_Aciertos</th>\n",
       "      <th>df_Errores</th>\n",
       "      <th>df_Indeterm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Distancia coseno</td>\n",
       "      <td>0.8</td>\n",
       "      <td>122</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.853147</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>0.874552</td>\n",
       "      <td>oracion subIntenc...</td>\n",
       "      <td>oracion...</td>\n",
       "      <td>oracion subI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regresión Logística Sin Regularización</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.908497</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>0.939189</td>\n",
       "      <td>oracion subIntenc...</td>\n",
       "      <td>oracion...</td>\n",
       "      <td>oracion subIn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Modelo  Umbral Aciertos Errores Indeterm  \\\n",
       "0                        Distancia coseno     0.8      122      14       21   \n",
       "1  Regresión Logística Sin Regularización     0.8      139      14        4   \n",
       "\n",
       "   Precision    Recall  Accuracy        F1  \\\n",
       "0   0.897059  0.853147  0.910828  0.874552   \n",
       "1   0.908497  0.972028  0.910828  0.939189   \n",
       "\n",
       "                                         df_Aciertos  \\\n",
       "0                               oracion subIntenc...   \n",
       "1                               oracion subIntenc...   \n",
       "\n",
       "                                          df_Errores  \\\n",
       "0                                         oracion...   \n",
       "1                                         oracion...   \n",
       "\n",
       "                                         df_Indeterm  \n",
       "0                                    oracion subI...  \n",
       "1                                   oracion subIn...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_comparativa.iloc[0].df_Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_comparativa.iloc[1].df_Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\tomas\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor accuracy: 0.8288\n",
      "Mejor C: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "RLog=LogisticRegression(penalty='none', max_iter=10000, tol=0.0001, multi_class='ovr',)\n",
    "\n",
    "parametros_RLog = {'C':[1]}\n",
    "\n",
    "grid_RLog1 = GridSearchCV(estimator = RLog,scoring = 'accuracy',param_grid = parametros_RLog, cv = 5, n_jobs = -1)\n",
    "\n",
    "grid_RLog1.fit(X[X.columns[1:]].values, y)\n",
    "\n",
    "\n",
    "AC_RLog_best=grid_RLog1.best_score_\n",
    "print('Mejor accuracy: ' + str(round(AC_RLog_best,4)))\n",
    "\n",
    "C_RLog_best=grid_RLog1.best_params_ \n",
    "print('Mejor C: ' + str(C_RLog_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros evaluados: 157\n",
      "--------------------\n",
      "Aciertos: 155\n",
      "Errores : 0\n",
      "Indeterm: 2\n",
      "--------------------\n",
      "Precision: 1.000 <- aciertos/(aciertos+errores)\n",
      "Recall   : 0.987 <- aciertos/(aciertos+indeterm)\n",
      "Accuracy : 1.000 <- (aciertos+indeterm)/(aciertos+errores+indeterm)\n",
      "F1       : 0.994 <- 2*((precision*recall)/(precision+recall))\n"
     ]
    }
   ],
   "source": [
    "Evaluar_Modelo(grid_RLog1, 'Regresión Logística Sin Regularización', X_test, y_test, umbral=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Grabar el modelo elegido\n",
    "\n",
    "pickle.dump(grid_RLog1, open(\"modelo_sub_intents.sav\", \"wb\"))\n",
    "\n",
    "# Grabar el vectorizador\n",
    "pickle.dump(vectorizador, open(\"vectorizador_sub_intents.pkl\", \"wb\"))\n",
    "\n",
    "pickle.dump(df_textos, open(r'df_matriz_sub_intents.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pedile al profe si puede pasar los enlaces de programacion logica."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d333c3e79956f6cfdda154d497169890c9e1b3b648807dd58683480f0849f8e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
