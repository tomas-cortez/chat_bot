{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "nlp=spacy.load('es_core_news_sm')\n",
    "\n",
    "# Stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "spanish_stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "# Levantamos la lista de StopWords\n",
    "f = open('stopwords_sin_w5.txt', 'r', encoding='utf8')\n",
    "stopwords = f.read().split('\\n')\n",
    "f.close()\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcesar(Corpus, POS=False, Lema=True, Stem=True):\n",
    "    \n",
    "    \n",
    "    # Generar una lista de documentos de spacy para tratar el POS Tagging y la Lematización\n",
    "    docs=[]\n",
    "    for oracion in Corpus:\n",
    "        docs.append(nlp(oracion.lower())) #La lematización funciona mejor en minúsculas\n",
    "    \n",
    "    # Crear una lista de oraciones, donde cada elemento es una lista de palabras.\n",
    "    # Cada palabra está definida por una tupla (Texto, POSTag, Lema)\n",
    "    # Se omiten los tokens que son identificados como signos de puntuación\n",
    "    oraciones=[]\n",
    "    for doc in docs:\n",
    "        oracion=[]\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'PUNCT':\n",
    "                oracion.append((token.text, token.pos_, token.lemma_))\n",
    "        oraciones.append(oracion)\n",
    "    \n",
    "    # Removemos StopWords (finándonos en el lema de cada palabra en vez de su texto!)\n",
    "    # No conviene quitar las StopWords antes de lematizar pues son útiles para ese proceso...\n",
    "    oraciones = [[palabra for palabra in oracion if palabra[2] not in stopwords] for oracion in oraciones]\n",
    "    \n",
    "    # Stemming\n",
    "    if Stem==True:\n",
    "        oraciones_aux=[]\n",
    "        for oracion in oraciones:\n",
    "            oracion_aux=[]\n",
    "            for palabra in oracion:\n",
    "                p_texto, p_pos, p_lema = palabra\n",
    "                # Si Lema es True, se Stemmatiza el lema; si no, se Stemmatiza la palabra original\n",
    "                if Lema==True:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_lema)))\n",
    "                else:\n",
    "                    oracion_aux.append((p_texto, p_pos, p_lema, spanish_stemmer.stem(p_texto)))\n",
    "            oraciones_aux.append(oracion_aux)\n",
    "        \n",
    "        oraciones = oraciones_aux\n",
    "    \n",
    "    # Finalmente: devolver nuevamente una lista de cadenas como la recibida, pero con el contenido\n",
    "    # de cada cadena conformado según los parámetros:\n",
    "    \n",
    "    Corpus_Procesado = [] #Variable de salida\n",
    "    \n",
    "    for doc in oraciones:\n",
    "        oracion = ''\n",
    "        for palabra in doc:\n",
    "            if Stem == True:\n",
    "                # Devolver cadena de Stemming\n",
    "                oracion = oracion + palabra[3]\n",
    "            else:\n",
    "                if Lema == True:\n",
    "                    # Devolver cadena de Lemas\n",
    "                    oracion = oracion + palabra[2]\n",
    "                else:\n",
    "                    # Devolver cadena de palabras originales\n",
    "                    oracion = oracion + palabra[0]\n",
    "            \n",
    "            if POS == True:\n",
    "                #Concatenar POS a cada palabra\n",
    "                oracion = oracion + '_' + palabra[1].lower()\n",
    "            \n",
    "            oracion = oracion + ' '\n",
    "        \n",
    "        Corpus_Procesado.append(oracion)\n",
    "        \n",
    "    return Corpus_Procesado\n",
    "\n",
    "def Corregir_Documentos(df_textos, columnas, POS=False, Lema=True, Stem=True):\n",
    "\n",
    "    for col in columnas:\n",
    "        df_textos[col] = PreProcesar(list(df_textos[col]), POS, Lema, Stem)\n",
    "    \n",
    "    # Sanear el DataFrame eliminando los duplicados y reindexándolo\n",
    "    df_textos = df_textos.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return df_textos\n",
    "\n",
    "def Generar_Matriz_BOW(df_textos, columna, binario=False, ngram=(1,2)):\n",
    "    \n",
    "    # Vectorizar, usando CountVectorizer de sklearn.feature_extraction.text\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizador = CountVectorizer(binary=binario, ngram_range=ngram)\n",
    "    X = vectorizador.fit_transform(df_textos[columna])\n",
    "    \n",
    "    # Generar el DataFrame a devolver\n",
    "    df_X = pd.DataFrame(X.toarray(), columns=vectorizador.get_feature_names())\n",
    "    df = df_textos.join(df_X)\n",
    "    \n",
    "    return vectorizador, df\n",
    "\n",
    "def Generar_Matriz_Tfidf(df_textos, columna, ngram=(1,2)):\n",
    "    \n",
    "    # Vectorizar... Directamente usar aquí el TfidfVectorizer de sklearn en vez del CountVectorizer\n",
    "    # (Lleva los mismos parámetros y directamente nos devuelve la matriz con los vectores Tf*Idf)\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizador = TfidfVectorizer(ngram_range=ngram)\n",
    "    X = vectorizador.fit_transform(df_textos[columna])\n",
    "    \n",
    "    # Generar el DataFrame a devolver\n",
    "    df_X = pd.DataFrame(X.toarray(), columns=vectorizador.get_feature_names())\n",
    "    df = df_textos.join(df_X)\n",
    "    \n",
    "    return vectorizador, df\n",
    "\n",
    "def Distancia_Coseno(u, v):\n",
    "\n",
    "    distancia = 1.0 - (np.dot(u, v) / (np.sqrt(sum(np.square(u))) * np.sqrt(sum(np.square(v)))))\n",
    "    return distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#1. Cargar y corregir el corpus\n",
    "df_textos = pd.read_csv('data_w5_.csv', sep=';', encoding='utf_8')\n",
    "df_textos = Corregir_Documentos(df_textos,['oracion'],False,True,True)\n",
    "\n",
    "#2. Modelizar los documentos de df_textos\n",
    "vectorizador, df_textos = Generar_Matriz_Tfidf(df_textos,'oracion',ngram=(1,2))\n",
    "#vectorizador, df_textos = Generar_Matriz_BOW(df_textos,'oracion')\n",
    "\n",
    "#3. Separar el corpus en Train/Test\n",
    "X = df_textos.drop(['w'],axis=1)\n",
    "y = df_textos[['w']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=124)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "      <th>w</th>\n",
       "      <th>carg</th>\n",
       "      <th>clas</th>\n",
       "      <th>cobr</th>\n",
       "      <th>com</th>\n",
       "      <th>com hac</th>\n",
       "      <th>com que</th>\n",
       "      <th>com ten</th>\n",
       "      <th>cost</th>\n",
       "      <th>...</th>\n",
       "      <th>tard</th>\n",
       "      <th>ten</th>\n",
       "      <th>ten que</th>\n",
       "      <th>ten tiemp</th>\n",
       "      <th>termin</th>\n",
       "      <th>termin plaz</th>\n",
       "      <th>tiemp</th>\n",
       "      <th>ubic</th>\n",
       "      <th>val</th>\n",
       "      <th>ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com</td>\n",
       "      <td>como</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com ten que hac</td>\n",
       "      <td>como</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331402</td>\n",
       "      <td>0.360852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com hac</td>\n",
       "      <td>como</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505665</td>\n",
       "      <td>0.677465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com ten que</td>\n",
       "      <td>como</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408568</td>\n",
       "      <td>0.444874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com que</td>\n",
       "      <td>como</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>que ten que hac</td>\n",
       "      <td>como</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317401</td>\n",
       "      <td>0.345606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cuand</td>\n",
       "      <td>cuando</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cuand empez</td>\n",
       "      <td>cuando</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cuand termin</td>\n",
       "      <td>cuando</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>que fech</td>\n",
       "      <td>cuando</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            oracion       w  carg  clas  cobr       com   com hac   com que  \\\n",
       "0              com     como   0.0   0.0   0.0  1.000000  0.000000  0.000000   \n",
       "1  com ten que hac     como   0.0   0.0   0.0  0.378915  0.000000  0.000000   \n",
       "2          com hac     como   0.0   0.0   0.0  0.505665  0.677465  0.000000   \n",
       "3      com ten que     como   0.0   0.0   0.0  0.467144  0.000000  0.000000   \n",
       "4          com que     como   0.0   0.0   0.0  0.556341  0.000000  0.745358   \n",
       "5  que ten que hac     como   0.0   0.0   0.0  0.000000  0.000000  0.000000   \n",
       "6            cuand   cuando   0.0   0.0   0.0  0.000000  0.000000  0.000000   \n",
       "7      cuand empez   cuando   0.0   0.0   0.0  0.000000  0.000000  0.000000   \n",
       "8     cuand termin   cuando   0.0   0.0   0.0  0.000000  0.000000  0.000000   \n",
       "9         que fech   cuando   0.0   0.0   0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "    com ten  cost  ...  tard       ten   ten que  ten tiemp    termin  \\\n",
       "0  0.000000   0.0  ...   0.0  0.000000  0.000000        0.0  0.000000   \n",
       "1  0.460139   0.0  ...   0.0  0.331402  0.360852        0.0  0.000000   \n",
       "2  0.000000   0.0  ...   0.0  0.000000  0.000000        0.0  0.000000   \n",
       "3  0.567280   0.0  ...   0.0  0.408568  0.444874        0.0  0.000000   \n",
       "4  0.000000   0.0  ...   0.0  0.000000  0.000000        0.0  0.000000   \n",
       "5  0.000000   0.0  ...   0.0  0.317401  0.345606        0.0  0.000000   \n",
       "6  0.000000   0.0  ...   0.0  0.000000  0.000000        0.0  0.000000   \n",
       "7  0.000000   0.0  ...   0.0  0.000000  0.000000        0.0  0.000000   \n",
       "8  0.000000   0.0  ...   0.0  0.000000  0.000000        0.0  0.634899   \n",
       "9  0.000000   0.0  ...   0.0  0.000000  0.000000        0.0  0.000000   \n",
       "\n",
       "   termin plaz  tiemp  ubic  val  ver  \n",
       "0          0.0    0.0   0.0  0.0  0.0  \n",
       "1          0.0    0.0   0.0  0.0  0.0  \n",
       "2          0.0    0.0   0.0  0.0  0.0  \n",
       "3          0.0    0.0   0.0  0.0  0.0  \n",
       "4          0.0    0.0   0.0  0.0  0.0  \n",
       "5          0.0    0.0   0.0  0.0  0.0  \n",
       "6          0.0    0.0   0.0  0.0  0.0  \n",
       "7          0.0    0.0   0.0  0.0  0.0  \n",
       "8          0.0    0.0   0.0  0.0  0.0  \n",
       "9          0.0    0.0   0.0  0.0  0.0  \n",
       "\n",
       "[10 rows x 109 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_textos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparativa = pd.DataFrame(columns=['Modelo','Umbral','Aciertos',\n",
    "'Errores','Indeterm','Precision','Recall','Accuracy','F1','df_Aciertos','df_Errores','df_Indeterm'])\n",
    "\n",
    "#Distancia_Coseno del profe\n",
    "\n",
    "def Evaluar_Modelo_Distancia_Coseno(X_train, X_test, y_test, umbral=0.8):\n",
    "    # Recorrer todo el Test Set prediciendo para cada oración de X_test y comparando con y_test\n",
    "    global df_comparativa\n",
    "    df_test = X_test[['oracion']].join(y_test)\n",
    "    array_X = X_train[X_train.columns[1:]].values\n",
    "    lista_distancia = [] #Distancia con el elemento más cercano (predicción)\n",
    "    lista_predic    = [] #Predicción del elemento más cercano\n",
    "    lista_similar   = [] #Texto del elemento más cercano\n",
    "    for test_doc in df_test.iterrows():\n",
    "        i,d = test_doc\n",
    "        df_query = pd.DataFrame([d['oracion']],columns=['oracion'])\n",
    "        Q = vectorizador.transform(df_query['oracion'])\n",
    "        distancia = [Distancia_Coseno(Q.A[0],fila) for fila in array_X]\n",
    "        df_Resultado = pd.DataFrame(distancia, columns=['Distancia']).join(X_train[['oracion']]).join(y_train[['w']]).sort_values(by='Distancia').head(1)\n",
    "\n",
    "        lista_distancia.append(df_Resultado.iloc[0]['Distancia'])\n",
    "        lista_predic.append(df_Resultado.iloc[0]['w']) \n",
    "        lista_similar.append(df_Resultado.iloc[0]['oracion'])\n",
    "\n",
    "    # Agregar columnas con resultados predichos al df_test\n",
    "    df_test['Distancia'] = lista_distancia\n",
    "    df_test['Predic']    = lista_predic\n",
    "    df_test['Similar']   = lista_similar\n",
    "\n",
    "    # Evaluar el resultado en df_test\n",
    "    print('Cantidad de registros evaluados:', len(df_test))\n",
    "    print('--------------------')\n",
    "    aciertos = df_test[ ( df_test['w'] == df_test['Predic'] ) & \n",
    "                        ( df_test['Distancia'] <= umbral ) ]['w'].count()\n",
    "    errores  = df_test[ ( df_test['w'] != df_test['Predic'] ) & \n",
    "                        ( df_test['Distancia'] <= umbral) ]['w'].count()\n",
    "    indeterm = df_test[ ( df_test['Distancia'] > umbral) ]['Distancia'].count()\n",
    "    print('Aciertos:', aciertos)\n",
    "    print('Errores :', errores)\n",
    "    print('Indeterm:', indeterm)\n",
    "    print('--------------------')\n",
    "    precision = aciertos/(aciertos+errores)\n",
    "    recall    = aciertos/(aciertos+indeterm)\n",
    "    accuracy  = (aciertos+indeterm)/(aciertos+errores+indeterm)\n",
    "    F1        = 2*((precision*recall)/(precision+recall))\n",
    "    print('Precision: {0:.3f} <- aciertos/(aciertos+errores)'.format(precision))\n",
    "    print('Recall   : {0:.3f} <- aciertos/(aciertos+indeterm)'.format(recall))\n",
    "    print('Accuracy : {0:.3f} <- (aciertos+indeterm)/(aciertos+errores+indeterm)'.format(accuracy))\n",
    "    print('F1       : {0:.3f} <- 2*((precision*recall)/(precision+recall))'.format(F1))\n",
    "\n",
    "    df_comparativa = df_comparativa.append({'Modelo': 'Distancia coseno',\n",
    "                                            'Umbral': umbral,\n",
    "                                            'Aciertos': aciertos,\n",
    "                                            'Errores': errores,\n",
    "                                            'Indeterm': indeterm,\n",
    "                                            'Precision': precision,\n",
    "                                            'Recall': recall,\n",
    "                                            'Accuracy': accuracy,\n",
    "                                            'F1': F1,\n",
    "                                            'df_Aciertos': df_test[ ( df_test['w'] == df_test['Predic'] ) & ( df_test['Distancia'] <= umbral ) ],\n",
    "                                            'df_Errores' : df_test[ ( df_test['w'] != df_test['Predic'] ) & ( df_test['Distancia'] <= umbral ) ],\n",
    "                                            'df_Indeterm': df_test[ ( df_test['Distancia'] > umbral ) ]\n",
    "                                            }, ignore_index=True)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros evaluados: 11\n",
      "--------------------\n",
      "Aciertos: 7\n",
      "Errores : 2\n",
      "Indeterm: 2\n",
      "--------------------\n",
      "Precision: 0.778 <- aciertos/(aciertos+errores)\n",
      "Recall   : 0.778 <- aciertos/(aciertos+indeterm)\n",
      "Accuracy : 0.818 <- (aciertos+indeterm)/(aciertos+errores+indeterm)\n",
      "F1       : 0.778 <- 2*((precision*recall)/(precision+recall))\n"
     ]
    }
   ],
   "source": [
    "Evaluar_Modelo_Distancia_Coseno(X_train, X_test, y_test, umbral=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor accuracy: 0.5472\n",
      "Mejor C: {'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear el modelo con los parámetros que no cambiarán: observar que no le pasamos el valor de C de regulrización\n",
    "RLog=LogisticRegression(penalty='none', max_iter=10000, tol=0.00001, multi_class='ovr',)\n",
    "\n",
    "# Armar el diccionario con el nombre y valores para los Hiperparámetros\n",
    "parametros_RLog = {'C':[1]}\n",
    "\n",
    "# Armar el GridSearchCV\n",
    "grid_RLog = GridSearchCV(estimator = RLog,scoring = 'accuracy',param_grid = parametros_RLog, cv = 5,\n",
    "                        n_jobs = -1)\n",
    "\n",
    "# Entrenar con el Train Set\n",
    "grid_RLog.fit(X_train[X_train.columns[1:]].values, y_train);\n",
    "\n",
    "# Obtener el mejor AC \n",
    "AC_RLog_best=grid_RLog.best_score_\n",
    "print('Mejor accuracy: ' + str(round(AC_RLog_best,4)))\n",
    "\n",
    "C_RLog_best=grid_RLog.best_params_ \n",
    "print('Mejor C: ' + str(C_RLog_best))\n",
    "###########################################################################################################\n",
    "def Evaluar_Modelo(modelo, nombre_modelo, X_test, y_test, umbral=0.7):\n",
    "    # Recorrer todo el Test Set prediciendo para cada oración de X_test y comparando con y_test\n",
    "    global df_comparativa\n",
    "    df_test = X_test[['oracion']].join(y_test)\n",
    "    lista_predic       = [] #Predicción\n",
    "    lista_probabilidad = [] #Probabilidad de la predicción\n",
    "    for test_doc in df_test.iterrows():\n",
    "        i,d = test_doc\n",
    "        df_query = pd.DataFrame([d['oracion']],columns=['oracion'])\n",
    "        Q = vectorizador.transform(df_query['oracion'])\n",
    "        pronostico = modelo.predict([Q.A[0]])\n",
    "        probabilidad = modelo.predict_proba([Q.A[0]])\n",
    "        lista_predic.append(pronostico[0])\n",
    "        lista_probabilidad.append(probabilidad[0].max())\n",
    "    \n",
    "    # Agregar columnas con resultados predichos al df_test\n",
    "    df_test['Probabilidad'] = lista_probabilidad\n",
    "    df_test['Predic'] = lista_predic\n",
    "    \n",
    "    # Evaluar el resultado en df_test\n",
    "    print('Cantidad de registros evaluados:', len(df_test))\n",
    "    print('--------------------')\n",
    "    aciertos = df_test[ ( df_test['w'] == df_test['Predic'] ) & \n",
    "                        ( df_test['Probabilidad'] >= umbral ) ]['w'].count()\n",
    "    errores  = df_test[ ( df_test['w'] != df_test['Predic'] ) & \n",
    "                        ( df_test['Probabilidad'] >= umbral) ]['w'].count()\n",
    "    indeterm = df_test[ ( df_test['Probabilidad'] < umbral) ]['Probabilidad'].count()\n",
    "    \n",
    "    print('Aciertos:', aciertos)\n",
    "    print('Errores :', errores)\n",
    "    print('Indeterm:', indeterm)\n",
    "    print('--------------------')\n",
    "    precision = aciertos/(aciertos+errores)\n",
    "    recall    = aciertos/(aciertos+indeterm)\n",
    "    accuracy  = (aciertos+indeterm)/(aciertos+errores+indeterm)\n",
    "    F1        = 2*((precision*recall)/(precision+recall))\n",
    "    print('Precision: {0:.3f} <- aciertos/(aciertos+errores)'.format(precision))\n",
    "    print('Recall   : {0:.3f} <- aciertos/(aciertos+indeterm)'.format(recall))\n",
    "    print('Accuracy : {0:.3f} <- (aciertos+indeterm)/(aciertos+errores+indeterm)'.format(accuracy))\n",
    "    print('F1       : {0:.3f} <- 2*((precision*recall)/(precision+recall))'.format(F1))\n",
    "\n",
    "    # Registrar Resultados\n",
    "    df_comparativa = df_comparativa.append({'Modelo': nombre_modelo,\n",
    "                                            'Umbral': umbral,\n",
    "                                            'Aciertos': aciertos,\n",
    "                                            'Errores': errores,\n",
    "                                            'Indeterm': indeterm,\n",
    "                                            'Precision': precision,\n",
    "                                            'Recall': recall,\n",
    "                                            'Accuracy': accuracy,\n",
    "                                            'F1': F1,\n",
    "                                            'df_Aciertos': df_test[ ( df_test['w'] == df_test['Predic'] ) & ( df_test['Probabilidad'] >= umbral ) ],\n",
    "                                            'df_Errores' : df_test[ ( df_test['w'] != df_test['Predic'] ) & ( df_test['Probabilidad'] >= umbral ) ],\n",
    "                                            'df_Indeterm': df_test[ ( df_test['Probabilidad'] < umbral ) ]\n",
    "                                            }, ignore_index=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros evaluados: 11\n",
      "--------------------\n",
      "Aciertos: 6\n",
      "Errores : 3\n",
      "Indeterm: 2\n",
      "--------------------\n",
      "Precision: 0.667 <- aciertos/(aciertos+errores)\n",
      "Recall   : 0.750 <- aciertos/(aciertos+indeterm)\n",
      "Accuracy : 0.727 <- (aciertos+indeterm)/(aciertos+errores+indeterm)\n",
      "F1       : 0.706 <- 2*((precision*recall)/(precision+recall))\n"
     ]
    }
   ],
   "source": [
    "Evaluar_Modelo(grid_RLog, 'Regresión Logística Sin Regularización', X_test, y_test, umbral=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Umbral</th>\n",
       "      <th>Aciertos</th>\n",
       "      <th>Errores</th>\n",
       "      <th>Indeterm</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>df_Aciertos</th>\n",
       "      <th>df_Errores</th>\n",
       "      <th>df_Indeterm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Distancia coseno</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>oracion       w  Distancia  Pre...</td>\n",
       "      <td>oracion      w  Distancia Predic S...</td>\n",
       "      <td>oracion       w  Distancia  Predic    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regresión Logística Sin Regularización</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>oracion       w  Probabilidad  ...</td>\n",
       "      <td>oracion       w  Probabilidad  Pre...</td>\n",
       "      <td>oracion       w  Probabilidad  Pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Modelo  Umbral Aciertos Errores Indeterm  \\\n",
       "0                        Distancia coseno     0.8        7       2        2   \n",
       "1  Regresión Logística Sin Regularización     0.8        6       3        2   \n",
       "\n",
       "   Precision    Recall  Accuracy        F1  \\\n",
       "0   0.777778  0.777778  0.818182  0.777778   \n",
       "1   0.666667  0.750000  0.727273  0.705882   \n",
       "\n",
       "                                         df_Aciertos  \\\n",
       "0                 oracion       w  Distancia  Pre...   \n",
       "1                 oracion       w  Probabilidad  ...   \n",
       "\n",
       "                                          df_Errores  \\\n",
       "0              oracion      w  Distancia Predic S...   \n",
       "1              oracion       w  Probabilidad  Pre...   \n",
       "\n",
       "                                         df_Indeterm  \n",
       "0          oracion       w  Distancia  Predic    ...  \n",
       "1               oracion       w  Probabilidad  Pr...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "      <th>w</th>\n",
       "      <th>Distancia</th>\n",
       "      <th>Predic</th>\n",
       "      <th>Similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>que oficin</td>\n",
       "      <td>donde</td>\n",
       "      <td>0.670934</td>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>que laboratori</td>\n",
       "      <td>donde</td>\n",
       "      <td>0.670934</td>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            oracion      w  Distancia Predic Similar\n",
       "3       que oficin   donde   0.670934    que    que \n",
       "10  que laboratori   donde   0.670934    que    que "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparativa.iloc[0].df_Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "      <th>w</th>\n",
       "      <th>Probabilidad</th>\n",
       "      <th>Predic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cuant sal</td>\n",
       "      <td>cuanto</td>\n",
       "      <td>0.995611</td>\n",
       "      <td>cuando</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      oracion       w  Probabilidad  Predic\n",
       "1  cuant sal   cuanto      0.995611  cuando"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparativa.iloc[1].df_Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor accuracy: 0.5636\n",
      "Mejor C: {'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "RLog=LogisticRegression(penalty='none', max_iter=10000, tol=0.00001, multi_class='ovr',)\n",
    "\n",
    "parametros_RLog = {'C':[1]}\n",
    "\n",
    "grid_RLog1 = GridSearchCV(estimator = RLog,scoring = 'accuracy',param_grid = parametros_RLog, cv = 5, n_jobs = -1)\n",
    "\n",
    "grid_RLog1.fit(X[X.columns[1:]].values, y)\n",
    "\n",
    "\n",
    "AC_RLog_best=grid_RLog1.best_score_\n",
    "print('Mejor accuracy: ' + str(round(AC_RLog_best,4)))\n",
    "\n",
    "C_RLog_best=grid_RLog1.best_params_ \n",
    "print('Mejor C: ' + str(C_RLog_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros evaluados: 11\n",
      "--------------------\n",
      "Aciertos: 11\n",
      "Errores : 0\n",
      "Indeterm: 0\n",
      "--------------------\n",
      "Precision: 1.000 <- aciertos/(aciertos+errores)\n",
      "Recall   : 1.000 <- aciertos/(aciertos+indeterm)\n",
      "Accuracy : 1.000 <- (aciertos+indeterm)/(aciertos+errores+indeterm)\n",
      "F1       : 1.000 <- 2*((precision*recall)/(precision+recall))\n"
     ]
    }
   ],
   "source": [
    "Evaluar_Modelo(grid_RLog1, 'Regresión Logística Sin Regularización', X_test, y_test, umbral=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pickle\n",
    "\n",
    "# Grabar el modelo elegido\n",
    "nombre_archivo='modelo_w5.sav'\n",
    "pickle.dump(grid_RLog1, open(nombre_archivo, 'wb'))\n",
    "\n",
    "# Grabar el vectorizador\n",
    "nombre_archivo='vectorizador_w5.sav'\n",
    "pickle.dump(vectorizador, open(nombre_archivo, 'wb'))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Grabar el modelo elegido\n",
    "\n",
    "pickle.dump(grid_RLog1, open(\"modelo_w5.sav\", \"wb\"))\n",
    "\n",
    "# Grabar el vectorizador\n",
    "pickle.dump(vectorizador, open(\"vectorizador_w5.pkl\", \"wb\"))\n",
    "\n",
    "pickle.dump(df_textos, open(r'df_matriz_carreras.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d333c3e79956f6cfdda154d497169890c9e1b3b648807dd58683480f0849f8e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
